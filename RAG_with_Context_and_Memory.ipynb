{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "### Construct retriever ###\n",
    "loader = PyPDFLoader(\"attention.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OllamaEmbeddings())\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm=Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "### Contextualize question ###\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "### Answer question ###\n",
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "Use three sentences maximum and keep the answer concise.\\\n",
    "\n",
    "{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Statefully manage chat history ###\n",
    "store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run b8ac40bb-2010-4178-8b98-6bc26eb16ef3 not found for run 168b13b0-35a2-4cd9-a02d-6773549b06ea. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Self-attention is a mechanism in neural networks that allows them to focus on specific parts of the input when processing it. It was introduced in the Transformer architecture, which is a simple network architecture based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Self-attention allows the model to weight different parts of the input equally, rather than relying on a fixed context or recurrence. This allows the model to capture long-range dependencies in the input and to handle variable-length inputs. In the context of machine translation, self-attention can help the model to better understand the relationships between words in a sentence and to generate more accurate translations.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What is Self-Attention?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 960da9fe-e2a6-477b-a12a-25e1ab22e861 not found for run c90e00a9-52aa-4c22-a58c-2f2d39f0e1d1. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are several common ways to do self-attention in neural networks:\\n\\n1. Multi-head attention: This is a variation of self-attention where the input is split into multiple attention heads, each with its own weight matrix. The outputs of these heads are then combined to form the final output.\\n2. Attention masking: This involves adding a mask to the input that indicates which parts of the input should be attended to and which should not.\\n3. Positional encoding: This involves adding a fixed vector to each input element based on its position in the sequence. This allows the model to differentiate between elements in the sequence even if they have the same content.\\n4. Layer normalization: This involves normalizing the activations of each layer in the network, which can help the model to focus on the relevant parts of the input.\\n5. Bidirectional encoding: This involves processing the input sequence in both the forward and backward directions, allowing the model to capture both local and global dependencies in the input.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What are common ways of doing it?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 718c30be-26f7-408c-93df-ee87275250e8 not found for run cd495eea-1375-4baa-9fee-b114f32f36fb. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You are primarily discussing self-attention in neural networks, specifically in the context of machine translation.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What am I primarily discussing about?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='What is Self-Attention?'), AIMessage(content='Self-attention is a mechanism in neural networks that allows them to focus on specific parts of the input when processing it. It was introduced in the Transformer architecture, which is a simple network architecture based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Self-attention allows the model to weight different parts of the input equally, rather than relying on a fixed context or recurrence. This allows the model to capture long-range dependencies in the input and to handle variable-length inputs. In the context of machine translation, self-attention can help the model to better understand the relationships between words in a sentence and to generate more accurate translations.'), HumanMessage(content='What are common ways of doing it?'), AIMessage(content='There are several common ways to do self-attention in neural networks:\\n\\n1. Multi-head attention: This is a variation of self-attention where the input is split into multiple attention heads, each with its own weight matrix. The outputs of these heads are then combined to form the final output.\\n2. Attention masking: This involves adding a mask to the input that indicates which parts of the input should be attended to and which should not.\\n3. Positional encoding: This involves adding a fixed vector to each input element based on its position in the sequence. This allows the model to differentiate between elements in the sequence even if they have the same content.\\n4. Layer normalization: This involves normalizing the activations of each layer in the network, which can help the model to focus on the relevant parts of the input.\\n5. Bidirectional encoding: This involves processing the input sequence in both the forward and backward directions, allowing the model to capture both local and global dependencies in the input.'), HumanMessage(content='What am I primarily discussing about?'), AIMessage(content='You are primarily discussing self-attention in neural networks, specifically in the context of machine translation.')])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_session_history(\"abc123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
